{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPARQL query preparation\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "endpoint = SPARQLWrapper(\"http://114.212.81.217:8890/sparql/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_item_with_relations_list(r_list,r_type=\"temporal fact\",result_path=\"\",t_type=\"period\"):\n",
    "    relation_stat=[]\n",
    "    for relation in r_list:\n",
    "        # variables for statistics for each relation\n",
    "        this_r_stat={}\n",
    "        this_r_stat[\"r\"]=relation\n",
    "        cnt=0\n",
    "        st_cnt=0\n",
    "        en_cnt=0\n",
    "        point_cnt=0\n",
    "        st_en_pair_cnt=0\n",
    "\n",
    "        # differrent query for different relation types\n",
    "        if r_type==\"temporal fact\":\n",
    "            query = '''\n",
    "                PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "                PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "                SELECT DISTINCT ?e1 ?e2 ?st ?en ?time\n",
    "                WHERE\n",
    "                {{\n",
    "                    ?e1 p:{} ?s.\n",
    "                    ?s ps:{} ?e2.\n",
    "                    ?s a <http://wikiba.se/ontology#Statement>.\n",
    "\n",
    "                    {{\n",
    "                        ?s pq:P580 ?st.\n",
    "                        OPTIONAL {{?s pq:P582 ?en.}}\n",
    "                        OPTIONAL {{?s pq:P585 ?time.}}\n",
    "                    }}\n",
    "                    UNION\n",
    "                    {{\n",
    "                        ?s pq:P582 ?en.\n",
    "                        OPTIONAL {{?s pq:P580 ?st.}}\n",
    "                        OPTIONAL {{?s pq:P585 ?time.}}\n",
    "                    }}\n",
    "                    UNION\n",
    "                    {{\n",
    "                        ?s pq:P585 ?time.\n",
    "                        OPTIONAL {{?s pq:P580 ?st.}}\n",
    "                        OPTIONAL{{?s pq:P582 ?en.}}\n",
    "                    }}\n",
    "                }}\n",
    "                '''.format(relation,relation)\n",
    "        elif r_type==\"time property\":\n",
    "            query = '''\n",
    "                PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "                PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "                SELECT DISTINCT ?e1 ?e2 ?st ?en\n",
    "                WHERE\n",
    "                {{\n",
    "                    ?e1 p:{} ?s.\n",
    "                    ?s ps:{} ?e2.\n",
    "\n",
    "                    OPTIONAL {{?s pq:P580 ?st.}}\n",
    "                    OPTIONAL {{?s pq:P582 ?en.}}\n",
    "                }}\n",
    "                '''.format(relation,relation)\n",
    "        # print(query)\n",
    "        endpoint.setQuery(query)\n",
    "        endpoint.setReturnFormat(JSON)\n",
    "        response = endpoint.query().convert()\n",
    "        results = response['results']['bindings']\n",
    "        print(\"%s Query complete!\" % relation)\n",
    "\n",
    "        # process query results\n",
    "        query_res=[]\n",
    "        for each_result in results:\n",
    "            temporal_fact={}\n",
    "\n",
    "            temporal_fact[\"s\"]=each_result[\"e1\"][\"value\"][31:]\n",
    "            temporal_fact[\"p\"]=relation\n",
    "\n",
    "            # process time info\n",
    "            # process point in time typed relation with \"point in time\"\n",
    "            if (\"time\" in each_result) and (t_type==\"point\"):\n",
    "                if each_result[\"time\"][\"type\"]==\"typed-literal\":\n",
    "                    if each_result[\"time\"][\"datatype\"]!=\"http://www.w3.org/2001/XMLSchema#dateTime\":\n",
    "                        print(\"DatatypeAlert!type:%s\",each_result[\"en\"][\"datatype\"])\n",
    "                    temporal_fact[\"t1\"]=each_result[\"time\"][\"value\"].split(\"T\")[0]\n",
    "                    temporal_fact[\"t2\"]=each_result[\"time\"][\"value\"].split(\"T\")[0]\n",
    "                else:\n",
    "                    continue # unexcepted datatype of time found, drop it\n",
    "            # process period typed relation\n",
    "            elif t_type==\"period\":\n",
    "                # first check if start time exists\n",
    "                if \"st\" in each_result:\n",
    "                    if each_result[\"st\"][\"type\"]==\"typed-literal\":\n",
    "                        if each_result[\"st\"][\"datatype\"]!=\"http://www.w3.org/2001/XMLSchema#dateTime\":\n",
    "                            print(\"DatatypeAlert!type:%s\",each_result[\"en\"][\"datatype\"])\n",
    "                        temporal_fact[\"t1\"]=each_result[\"st\"][\"value\"].split(\"T\")[0]\n",
    "                    else:\n",
    "                        continue # unexcepted datatype of time found, drop it\n",
    "                else:\n",
    "                    temporal_fact[\"t1\"]=\"null\"\n",
    "\n",
    "                # then check if end time exists\n",
    "                if \"en\" in each_result:\n",
    "                    if each_result[\"en\"][\"type\"]==\"typed-literal\":\n",
    "                        if each_result[\"en\"][\"datatype\"]!=\"http://www.w3.org/2001/XMLSchema#dateTime\":\n",
    "                            print(\"DatatypeAlert!type:%s\",each_result[\"en\"][\"datatype\"])\n",
    "                        temporal_fact[\"t2\"]=each_result[\"en\"][\"value\"].split(\"T\")[0]\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    temporal_fact[\"t2\"]=\"null\" # unexcepted datatype of time found, drop it\n",
    "\n",
    "                # none of start and end time exists, use point of time\n",
    "                if (temporal_fact[\"t1\"]==\"null\") and (temporal_fact[\"t2\"]==\"null\"):\n",
    "                    if \"time\" in each_result:\n",
    "                        if each_result[\"time\"][\"type\"]==\"typed-literal\":\n",
    "                            if each_result[\"time\"][\"datatype\"]!=\"http://www.w3.org/2001/XMLSchema#dateTime\":\n",
    "                                print(\"DatatypeAlert!type:%s\",each_result[\"en\"][\"datatype\"])\n",
    "                            temporal_fact[\"t1\"]=each_result[\"time\"][\"value\"].split(\"T\")[0]\n",
    "                            temporal_fact[\"t2\"]=each_result[\"time\"][\"value\"].split(\"T\")[0]\n",
    "                        else:\n",
    "                            continue # unexcepted datatype of time found, drop it\n",
    "                    elif r_type==\"temporal fact\":\n",
    "                        continue # point in time also not exists\n",
    "\n",
    "            # process object(tail entity) info\n",
    "            # for temporal facts\n",
    "            if each_result[\"e2\"][\"type\"]==\"uri\":\n",
    "                temporal_fact[\"o\"]=each_result[\"e2\"][\"value\"][31:]\n",
    "            #for time property\n",
    "            elif each_result[\"e2\"][\"type\"]==\"typed-literal\":\n",
    "                if each_result[\"e2\"][\"datatype\"]!=\"http://www.w3.org/2001/XMLSchema#dateTime\":\n",
    "                    print(\"DatatypeAlert!type:%s\",each_result[\"en\"][\"datatype\"])\n",
    "                temporal_fact[\"o\"]=each_result[\"e2\"][\"value\"].split(\"T\")[0]\n",
    "                # if temporal_fact[\"t1\"]==\"null\" and temporal_fact[\"t2\"]==\"null\":\n",
    "                temporal_fact[\"t1\"]=temporal_fact[\"o\"]\n",
    "                temporal_fact[\"t2\"]=temporal_fact[\"o\"]\n",
    "            else:\n",
    "                continue # for unexcepted datatype of object\n",
    "\n",
    "            if \"st\" in each_result:\n",
    "                st_cnt+=1\n",
    "            if \"en\" in each_result:\n",
    "                en_cnt+=1\n",
    "            if (\"st\" in each_result)and(\"en\" in each_result):\n",
    "                st_en_pair_cnt+=1\n",
    "            if \"time\" in each_result:\n",
    "                point_cnt+=1\n",
    "            cnt+=1\n",
    "            query_res.append(temporal_fact)\n",
    "\n",
    "        this_r_stat[\"cnt\"]=cnt\n",
    "        this_r_stat[\"st_cnt\"]=st_cnt\n",
    "        this_r_stat[\"en_cnt\"]=en_cnt\n",
    "        this_r_stat[\"st_en_pair_ent\"]=st_en_pair_cnt\n",
    "        this_r_stat[\"point_cnt\"]=point_cnt\n",
    "        relation_stat.append(this_r_stat)\n",
    "        f=open(\"%s/%sres.csv\" %(result_path,relation),\"w\")\n",
    "        for tf in query_res:\n",
    "            f.write(\"%s,%s,%s,%s,%s\\n\" %(tf[\"s\"],tf[\"p\"],tf[\"o\"],tf[\"t1\"],tf[\"t2\"]))\n",
    "        f.close()\n",
    "    return relation_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optional relation info\n",
    "tr_file=open(\"property final.tsv\")\n",
    "line=tr_file.readline()\n",
    "line=tr_file.readline()\n",
    "optional_relation_list=[]\n",
    "while line:\n",
    "    relation=line.split('\\t')[0][32:-1]\n",
    "    optional_relation_list.append(relation)\n",
    "    line=tr_file.readline()\n",
    "# print(optional_relation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required relations\n",
    "common_relation_list=['P26', 'P108', 'P54', 'P286']\n",
    "timeobj_relation_list=['P569', 'P570']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P26 Query complete!\n",
      "P108 Query complete!\n",
      "P54 Query complete!\n",
      "P286 Query complete!\n",
      "Phase 1 done.\n"
     ]
    }
   ],
   "source": [
    "# phase 1 for temporal relations in required relations (all period)\n",
    "stat_info=get_all_item_with_relations_list(common_relation_list,\"temporal fact\",\"raw/required/common/\")\n",
    "print(\"Phase 1 done.\")\n",
    "\n",
    "statfilename=\"PHASE1_RELATION_STAT.txt\"\n",
    "f=open(statfilename,\"w\")\n",
    "f.write(\"?relation\\t?count\\t?st_count\\t?en_count\\t?st_en_pairs_count\\t?point_count\\n\")\n",
    "for this_r_stat in stat_info:\n",
    "    f.write(\"%s\\t%d\\t%d\\t%d\\t%d\\t%d\\n\" %(this_r_stat[\"r\"],this_r_stat[\"cnt\"],this_r_stat[\"st_cnt\"],this_r_stat[\"en_cnt\"],this_r_stat[\"st_en_pair_ent\"],this_r_stat[\"point_cnt\"]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P569 Query complete!\n",
      "P570 Query complete!\n",
      "Phase 2 done.\n"
     ]
    }
   ],
   "source": [
    "# phase 2 for time property in required relations\n",
    "stat_info=get_all_item_with_relations_list(timeobj_relation_list,\"time property\",\"raw/required/time_prop\")\n",
    "print(\"Phase 2 done.\")\n",
    "\n",
    "statfilename=\"PHASE2_RELATION_STAT.txt\"\n",
    "f=open(statfilename,\"w\")\n",
    "f.write(\"?relation\\t?count\\t?st_count\\t?en_count\\t?st_en_pairs_count\\t?point_count\\n\")\n",
    "for this_r_stat in stat_info:\n",
    "    f.write(\"%s\\t%d\\t%d\\t%d\\t%d\\t%d\\n\" %(this_r_stat[\"r\"],this_r_stat[\"cnt\"],this_r_stat[\"st_cnt\"],this_r_stat[\"en_cnt\"],this_r_stat[\"st_en_pair_ent\"],this_r_stat[\"point_cnt\"]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phase 3 for all optional relations (suppose they are all period)\n",
    "stat_info=get_all_item_with_relations_list(optional_relation_list,\"temporal fact\",\"raw/optional/common\")\n",
    "print(\"Phase 3 done.\")\n",
    "\n",
    "statfilename=\"PHASE3_RELATION_STAT.txt\"\n",
    "f=open(statfilename,\"w\")\n",
    "f.write(\"?relation\\t?count\\t?st_count\\t?en_count\\t?st_en_pairs_count\\t?point_count\\n\")\n",
    "for this_r_stat in stat_info:\n",
    "    f.write(\"%s\\t%d\\t%d\\t%d\\t%d\\t%d\\n\" %(this_r_stat[\"r\"],this_r_stat[\"cnt\"],this_r_stat[\"st_cnt\"],this_r_stat[\"en_cnt\"],this_r_stat[\"st_en_pair_ent\"],this_r_stat[\"point_cnt\"]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw/required/common/P26res.csv\n",
      "raw/required/common/P108res.csv\n",
      "raw/required/common/P286res.csv\n",
      "raw/required/common/P54res.csv\n",
      "raw/required/time_prop/P570res.csv\n",
      "raw/required/time_prop/P569res.csv\n"
     ]
    }
   ],
   "source": [
    "# merge files into dataset\n",
    "import os\n",
    "dir_list=[\"raw/required/common/\",\"raw/required/time_prop/\"]\n",
    "r_list=[]\n",
    "dataset_name=\"required_relations\"\n",
    "dataset_version=\"alpha-1\"\n",
    "merged_f=open(dataset_name+\"_\"+dataset_version+\".csv\",\"w\")\n",
    "for each_dir in dir_list:\n",
    "    all_obj=os.listdir(each_dir)\n",
    "    for each_obj in all_obj:\n",
    "        if each_obj.endswith(\"res.csv\"):\n",
    "            read_f=open(each_dir+each_obj,\"r\")\n",
    "            file_content=read_f.read()\n",
    "            merged_f.write(file_content)\n",
    "            read_f.close()\n",
    "            print(each_dir+each_obj)\n",
    "merged_f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test temporal fact query sparql\n",
    "relation=\"P1789\"\n",
    "query = '''\n",
    "    PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "    SELECT DISTINCT ?e1 ?e2 ?st ?en\n",
    "    WHERE\n",
    "    {{\n",
    "        ?e1 p:{} ?s.\n",
    "        ?s ps:{} ?e2.\n",
    "\n",
    "        {{?s pq:P580 ?st.\n",
    "        OPTIONAL {{?s pq:P582 ?en.}}}}\n",
    "        UNION\n",
    "        {{?s pq:P582 ?en.\n",
    "        OPTIONAL {{?s pq:P580 ?st.}}}}\n",
    "    }}\n",
    "    '''.format(relation,relation)\n",
    "# print(query)\n",
    "endpoint.setQuery(query)\n",
    "endpoint.setReturnFormat(JSON)\n",
    "response = endpoint.query().convert()\n",
    "results = response['results']['bindings']\n",
    "print(results)\n",
    "query_res=[]\n",
    "print(\"%s Query complete!\" % relation)\n",
    "for each_result in results:\n",
    "    temporal_fact={}\n",
    "    temporal_fact[\"s\"]=each_result[\"e1\"][\"value\"][31:]\n",
    "    temporal_fact[\"p\"]=relation\n",
    "    temporal_fact[\"o\"]=each_result[\"e2\"][\"value\"][31:]\n",
    "    \n",
    "    if \"st\" in each_result:\n",
    "        if each_result[\"st\"][\"type\"]==\"typed-literal\":\n",
    "            if each_result[\"st\"][\"datatype\"]!=\"http://www.w3.org/2001/XMLSchema#dateTime\":\n",
    "                print(\"DatatypeAlert!type:%s\",each_result[\"en\"][\"datatype\"])\n",
    "            temporal_fact[\"t1\"]=each_result[\"st\"][\"value\"].split(\"T\")[0]\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        temporal_fact[\"t1\"]=\"null\"\n",
    "    if \"en\" in each_result:\n",
    "        if each_result[\"en\"][\"type\"]==\"typed-literal\":\n",
    "            if each_result[\"en\"][\"datatype\"]!=\"http://www.w3.org/2001/XMLSchema#dateTime\":\n",
    "                print(\"DatatypeAlert!type:%s\",each_result[\"en\"][\"datatype\"])\n",
    "            temporal_fact[\"t2\"]=each_result[\"en\"][\"value\"].split(\"T\")[0]\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        temporal_fact[\"t2\"]=\"null\"\n",
    "    query_res.append(temporal_fact)\n",
    "\n",
    "# f=open(\"%sres.csv\" %relation,\"w\")\n",
    "# for tf in query_res:\n",
    "#     f.write(\"%s,%s,%s,%s,%s\\n\" %(tf[\"s\"],tf[\"p\"],tf[\"o\"],tf[\"t1\"],tf[\"t2\"]))\n",
    "# f.close()\n",
    "# print(query_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test time property query sparql\n",
    "relation=\"P569\"\n",
    "query = '''\n",
    "        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        SELECT  ?e1 \\\"{}\\\" ?time\n",
    "        WHERE\n",
    "        {{\n",
    "            ?e1 wdt:{} ?time.\n",
    "        }}\n",
    "    '''.format(relation,relation)\n",
    "# print(query)\n",
    "endpoint.setQuery(query)\n",
    "endpoint.setReturnFormat(JSON)\n",
    "response = endpoint.query().convert()\n",
    "results = response['results']['bindings']\n",
    "print(results)\n",
    "query_res=[]\n",
    "print(\"%s Query complete!\" % relation)\n",
    "for each_result in results:\n",
    "    if \"literal\" in each_result[\"time\"][\"type\"]:\n",
    "        temporal_fact={}\n",
    "        temporal_fact[\"s\"]=each_result[\"e1\"][\"value\"][31:]\n",
    "        temporal_fact[\"p\"]=each_result[\"callret-1\"][\"value\"]\n",
    "        temporal_fact[\"o\"]=each_result[\"time\"][\"value\"]\n",
    "        temporal_fact[\"t1\"]=each_result[\"time\"][\"value\"]\n",
    "        temporal_fact[\"t2\"]=each_result[\"time\"][\"value\"]\n",
    "        query_res.append(temporal_fact)\n",
    "# f=open(\"%sres.csv\" %relation,\"w\")\n",
    "# for tf in query_res:\n",
    "#     f.write(\"%s,%s,%s,%s,%s\\n\" %(tf[\"s\"],tf[\"p\"],tf[\"o\"],tf[\"t1\"],tf[\"t2\"]))\n",
    "# f.close()\n",
    "# print(query_res)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
